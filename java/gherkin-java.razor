//      This code was generated by Berp (http://https://github.com/gasparnagy/berp/).
//
//      Changes to this file may cause incorrect behavior and will be lost if
//      the code is regenerated.

@using Berp;
@helper CallProduction(ProductionRule production)
{
    switch(production.Type) {
        case ProductionRuleType.Start:
                @:startRule(context, RuleType.@production.RuleName);
            break;
        case ProductionRuleType.End:
                @:endRule(context, RuleType.@production.RuleName);
            break;
        case ProductionRuleType.Process:
                @:build(context, token);
            break;
    }
}
@helper HandleParserError(IEnumerable<string> expectedTokens, State state)
{<text>
        final String stateComment = "State: @state.Id - @Raw(state.Comment)";
        token.detach();
        List<String> expectedTokens = asList("@Raw(string.Join("\", \"", expectedTokens))");
        ParserException error = token.isEOF()
                ? new ParserException.UnexpectedEOFException(token, expectedTokens, stateComment)
                : new ParserException.UnexpectedTokenException(token, expectedTokens, stateComment);
        if (stopAtFirstError)
            throw error;

        addError(context, error);
        return @state.Id;
</text>}
@helper matchToken(TokenType tokenType)
{<text>match_@(tokenType)(context, token)</text>}

package gherkin;

import java.io.Reader;
import java.io.StringReader;
import java.util.ArrayDeque;
import java.util.ArrayList;
import java.util.LinkedList;
import java.util.List;
import java.util.Queue;

import static java.util.Arrays.asList;

public class @Model.ParserClassName<T> {
    public enum TokenType {
        None,
        @foreach(var rule in Model.RuleSet.TokenRules)
        {<text>        @rule.Name.Replace("#", ""),
</text>}        ;
    }

    public enum RuleType {
        None,
        @foreach(var rule in Model.RuleSet.Where(r => !r.TempRule))
        {<text>        @rule.Name.Replace("#", "_"), // @rule.ToString(true)
</text>}        ;

        public static RuleType cast(TokenType tokenType) {
            return RuleType.values()[tokenType.ordinal()];
        }
    }


    public boolean stopAtFirstError;

    class ParserContext {
        public final ITokenScanner tokenScanner;
        public final ITokenMatcher tokenMatcher;
        public final IAstBuilder<T> builder;
        public final Queue<Token> tokenQueue;
        public final List<ParserException> errors;

        ParserContext(ITokenScanner tokenScanner, ITokenMatcher tokenMatcher, IAstBuilder<T> builder, Queue<Token> tokenQueue, List<ParserException> errors) {
            this.tokenScanner = tokenScanner;
            this.tokenMatcher = tokenMatcher;
            this.builder = builder;
            this.tokenQueue = tokenQueue;
            this.errors = errors;
        }
    }

    public T parse(String source, ITokenMatcher tokenMatcher) {
        return parse(new StringReader(source), tokenMatcher);
    }

    public T parse(Reader source, ITokenMatcher tokenMatcher) {
        AstBuilder<T> builder = new AstBuilder();
        return parse(source, builder, tokenMatcher);
    }

    public T parse(Reader source, IAstBuilder<T> builder, ITokenMatcher tokenMatcher) {
        ParserContext context = new ParserContext(
                new TokenScanner(source),
                tokenMatcher,
                builder,
                new LinkedList<Token>(),
                new ArrayList<ParserException>()
        );

        startRule(context, RuleType.Feature);
        int state = 0;
        Token token;
        do {
            token = readToken(context);
            state = matchToken(state, token, context);
        } while (!token.isEOF());

        endRule(context, RuleType.Feature);

        if (context.errors.size() > 0) {
            throw new ParserException.CompositeParserException(context.errors);
        }

        return getResult(context);
    }

    private void addError(ParserContext context, ParserException error) {
        context.errors.add(error);
        if (context.errors.size() > 10)
            throw new ParserException.CompositeParserException(context.errors);
    }

    private <V> V handleAstError(ParserContext context, final Func<V> action) {
        return handleExternalError(context, action, null);
    }

    private <V> V handleExternalError(ParserContext context, Func<V> action, V defaultValue) {
        if (stopAtFirstError) {
            return action.call();
        }

        try {
            return action.call();
        } catch (ParserException.CompositeParserException compositeParserException) {
            for (ParserException error : compositeParserException.errors) {
                addError(context, error);
            }
        } catch (ParserException error) {
            addError(context, error);
        }
        return defaultValue;
    }

    void build(final ParserContext context, final Token token) {
        handleAstError(context, new Func<Void>() {
            public Void call() {
                context.builder.build(token);
                return null;
            }
        });
    }

    void startRule(final ParserContext context, final RuleType ruleType) {
        handleAstError(context, new Func<Void>() {
            public Void call() {
                context.builder.startRule(ruleType);
                return null;
            }
        });
    }

    void endRule(final ParserContext context, final RuleType ruleType) {
        handleAstError(context, new Func<Void>() {
            public Void call() {
                context.builder.endRule(ruleType);
                return null;
            }
        });
    }

    T getResult(ParserContext context)
    {
        return context.builder.getResult();
    }

    Token readToken(ParserContext context)
    {
        return context.tokenQueue.size() > 0 ? context.tokenQueue.remove() : context.tokenScanner.read();
    }

@foreach(var rule in Model.RuleSet.TokenRules)
{<text>
    boolean match_@(rule.Name.Replace("#", ""))(final ParserContext context, final Token token) {
        @if (rule.Name != "#EOF")
        {
        @:if (token.isEOF()) return false;
        }
        return handleExternalError(context, new Func<Boolean>() {
            public Boolean call() {
                return context.tokenMatcher.match_@(rule.Name.Replace("#", ""))(token);
            }
        }, false);
    }</text>
}

    int matchToken(int state, Token token, ParserContext context) {
        int newState;
        switch(state)
        {
        @foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
        {
            @:case @state.Id:
                @:newState = matchTokenAt_@(state.Id)(token, context);
                @:break;
        }
            default:
                throw new IllegalStateException("Unknown state: " + state);
        }
        return newState;
    }

@foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
{
<text>
    // @Raw(state.Comment)
    int matchTokenAt_@(state.Id)(Token token, ParserContext context) {
        @foreach(var transition in state.Transitions)
        {
        @:if (@matchToken(transition.TokenType))
        @:{
            if (transition.LookAheadHint != null)
            {
            @:if (lookahead_@(transition.LookAheadHint.Id)(context, token))
            @:{
            }
            foreach(var production in transition.Productions)
            {
                @CallProduction(production)
            }
            @:return @transition.TargetState;
            if (transition.LookAheadHint != null)
            {
            @:}
            }
        @:}
        }
        @HandleParserError(state.Transitions.Select(t => "#" + t.TokenType.ToString()).Distinct(), state)
    }
</text>
}

@foreach(var lookAheadHint in Model.RuleSet.LookAheadHints)
{
<text>
    boolean lookahead_@(lookAheadHint.Id)(ParserContext context, Token currentToken) {
        currentToken.detach();
        Token token;
        Queue<Token> queue = new ArrayDeque<Token>();
        boolean match = false;
        do
        {
            token = readToken(context);
            token.detach();
            queue.add(token);

            if (false
            @foreach(var tokenType in lookAheadHint.ExpectedTokens)
            {
                @:|| @matchToken(tokenType)
            }
            )
            {
                match = true;
                break;
            }
        } while (false
        @foreach(var tokenType in lookAheadHint.Skip)
        {
            @:|| @matchToken(tokenType)
        }
        );

        context.tokenQueue.addAll(queue);

        return match;
    }
</text>
}

    public interface IAstBuilder<T> {
        void build(Token token);
        void startRule(RuleType ruleType);
        void endRule(RuleType ruleType);
        T getResult();
    }

    public interface ITokenScanner {
        Token read();
    }

    public interface ITokenMatcher {
        @foreach(var rule in Model.RuleSet.TokenRules)
        {
        @:boolean match_@(rule.Name.Replace("#", ""))(Token token);
        }
    }
}
